{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Terrain Classification using Convolutional Neural Networks\n",
        "This notebook demonstrates how to build and train a Convolutional Neural Network (CNN) for classifying terrain images into five categories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Installing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install tensorflow\n",
        "pip install scipy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importing Libraries\n",
        "\n",
        "Now we'll import the necessary libraries and modules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Architecture\n",
        "\n",
        "We'll define a CNN model for our terrain classification task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "\n",
        "    # Input layer\n",
        "    tf.keras.layers.Input(shape=(64, 64, 3)),\n",
        "    \n",
        "    # First convolutional layer\n",
        "    tf.keras.layers.Conv2D(32, kernel_size=3, activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=2, strides=2),\n",
        "    \n",
        "    # Second convolutional layer\n",
        "    tf.keras.layers.Conv2D(64, kernel_size=3, activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=2, strides=2),\n",
        "    \n",
        "    # Fully connected classifier\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(1024, activation='relu'),\n",
        "    tf.keras.layers.Dense(5, activation='softmax')\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Compilation\n",
        "\n",
        "We'll compile the model with appropriate loss function and optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Could also use sparse_categorical_crossentropy if they are indices instead of hot encoded labels\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Preprocessing\n",
        "\n",
        "We'll set up data generators for training and testing data, including data augmentation for the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   rotation_range=30,\n",
        "                                   brightness_range=[0.8, 1.2],\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 10000 images belonging to 5 classes.\n",
            "Found 500 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "# Update the directory paths to point to your local Downloads folder\n",
        "training_set = train_datagen.flow_from_directory(r'C:\\Users\\draka\\Downloads\\Terrain_Images\\Training Data',\n",
        "                                                 target_size=(64, 64),\n",
        "                                                 batch_size=64,\n",
        "                                                 class_mode='categorical')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory(r'C:\\Users\\draka\\Downloads\\Terrain_Images\\Testing Data',\n",
        "                                            target_size=(64, 64),\n",
        "                                            batch_size=64,\n",
        "                                            class_mode='categorical')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Learning Rate Scheduling\n",
        "\n",
        "We'll define a learning rate schedule to adjust the learning rate during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the learning rate schedule\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch < 10:\n",
        "        return 1e-2\n",
        "    else:\n",
        "        return 1e-3\n",
        "\n",
        "lr_schedule = LearningRateScheduler(scheduler)\n",
        "lr_reduction = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Training\n",
        "\n",
        "Now we'll train the model on our dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 7ms/step - accuracy: 0.6969 - loss: 0.7870 - val_accuracy: 0.7321 - val_loss: 0.7718\n",
            "Epoch 2/10\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 7ms/step - accuracy: 0.7108 - loss: 0.7600 - val_accuracy: 0.7692 - val_loss: 0.7620\n",
            "Epoch 3/10\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.7157 - loss: 0.7431 - val_accuracy: 0.7433 - val_loss: 0.6570\n",
            "Epoch 4/10\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 7ms/step - accuracy: 0.7263 - loss: 0.7289 - val_accuracy: 0.7885 - val_loss: 0.6065\n",
            "Epoch 5/10\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.7320 - loss: 0.7129 - val_accuracy: 0.7812 - val_loss: 0.5878\n",
            "Epoch 6/10\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 7ms/step - accuracy: 0.7377 - loss: 0.6902 - val_accuracy: 0.8269 - val_loss: 0.4793\n",
            "Epoch 7/10\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.7383 - loss: 0.6886 - val_accuracy: 0.8058 - val_loss: 0.5368\n",
            "Epoch 8/10\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 7ms/step - accuracy: 0.7497 - loss: 0.6671 - val_accuracy: 0.6923 - val_loss: 0.9142\n",
            "Epoch 9/10\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 7ms/step - accuracy: 0.7493 - loss: 0.6614 - val_accuracy: 0.7969 - val_loss: 0.5924\n",
            "Epoch 10/10\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 7ms/step - accuracy: 0.7600 - loss: 0.6433 - val_accuracy: 0.8269 - val_loss: 0.5042\n"
          ]
        }
      ],
      "source": [
        "modelZ = model.fit(\n",
        "    training_set,\n",
        "    steps_per_epoch=5000,\n",
        "    epochs=10,\n",
        "    validation_data=test_set,\n",
        "    validation_steps=7\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GPU Availability Check\n",
        "\n",
        "Let's check if any GPUs are available for training acceleration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  0\n"
          ]
        }
      ],
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
